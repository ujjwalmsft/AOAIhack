{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../configs/user_config.yaml\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "load_dotenv(\"../configs/environment_variables.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledgebase Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"financial_regulations\"\n",
    "DATA_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.generative.index import build_index\n",
    "from azure.ai.resources.client import AIClient\n",
    "from azure.ai.resources.operations._index_data_source import (\n",
    "    ACSOutputConfig,\n",
    "    LocalSource,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cogsearch_index(\n",
    "    index_name: str,\n",
    "    path_to_data: str,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    data_source_url: str = None,\n",
    "):\n",
    "    # Set up environment variables for cog search SDK\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_TARGET\"] = os.environ.get(\n",
    "        \"AZURE_AI_SEARCH_ENDPOINT\", \"\"\n",
    "    )\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_KEY\"] = os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")\n",
    "\n",
    "    client = AIClient.from_config(DefaultAzureCredential())\n",
    "\n",
    "    default_aoai_connection = client.get_default_aoai_connection()\n",
    "    default_aoai_connection.set_current_environment()\n",
    "\n",
    "    default_acs_connection = client.connections.get(\n",
    "        os.environ.get(\"AZURE_COGNITIVE_SEARCH_CONNECTION_NAME\", \"\")\n",
    "    )\n",
    "    default_acs_connection.set_current_environment()\n",
    "\n",
    "    # Use the same index name when registering the index in AI Studio\n",
    "    index = build_index(\n",
    "        output_index_name=index_name,\n",
    "        vector_store=os.environ.get(\"VECTOR_STORE\", \"\"),\n",
    "        embeddings_model=f\"azure_open_ai://deployment/{os.environ.get('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')}/model/{os.environ.get('AZURE_OPENAI_EMBEDDING_MODEL')}\",\n",
    "        data_source_url=data_source_url,\n",
    "        index_input_config=LocalSource(input_data=path_to_data),\n",
    "        acs_config=ACSOutputConfig(\n",
    "            acs_index_name=index_name,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    # register the index so that it shows up in the project\n",
    "    cloud_index = client.indexes.create_or_update(index)\n",
    "\n",
    "    print(f\"Created index '{cloud_index.name}'\")\n",
    "    print(f\"Local Path: {index.path}\")\n",
    "    print(f\"Cloud Path: {cloud_index.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cogsearch_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    path_to_data=DATA_PATH,\n",
    "    chunk_size=model_config[\"rag\"][\"chunk_size\"],\n",
    "    chunk_overlap=model_config[\"rag\"][\"chunk_overlap\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with Documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"financial_regulations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import nest_asyncio\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_documents(\n",
    "    question: str,\n",
    "    index_name: str,\n",
    "    num_docs=5,\n",
    ") -> str:\n",
    "    #  retrieve documents relevant to the user's question from Cognitive Search\n",
    "    search_client = SearchClient(\n",
    "        endpoint=os.environ.get(\"AZURE_AI_SEARCH_ENDPOINT\", \"\"),\n",
    "        credential=AzureKeyCredential(os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")),\n",
    "        index_name=index_name,\n",
    "    )\n",
    "\n",
    "    async with AsyncAzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as aclient:\n",
    "\n",
    "        # generate a vector embedding of the user's question\n",
    "        embedding = await aclient.embeddings.create(\n",
    "            input=question, model=os.environ.get(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "        )\n",
    "        embedding_to_query = embedding.data[0].embedding\n",
    "\n",
    "    context = \"\"\n",
    "    contexts = []\n",
    "    async with search_client:\n",
    "        # use the vector embedding to do a vector search on the index\n",
    "        vector_query = RawVectorQuery(\n",
    "            vector=embedding_to_query, k=num_docs, fields=\"contentVector\"\n",
    "        )\n",
    "        results = await search_client.search(\n",
    "            search_text=\"\", vector_queries=[vector_query], select=[\"id\", \"content\"]\n",
    "        )\n",
    "\n",
    "        async for result in results:\n",
    "            context += f\"\\n>>> {result['content']}\"\n",
    "            contexts.append(result[\"content\"])\n",
    "\n",
    "    return context, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_message(user_prompt: str, system_role: str) -> List[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "def chat_completion(\n",
    "    question: str,\n",
    "    system_role: str,\n",
    "    user_prompt: str,\n",
    "    index_name: str,\n",
    "    num_docs: int = 5,\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 800,\n",
    "):\n",
    "    # get search documents for the last user message in the conversation\n",
    "    context, contexts = asyncio.run(\n",
    "        get_documents(\n",
    "            question=question,\n",
    "            index_name=index_name,\n",
    "            num_docs=num_docs,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # TODO: Add context to user message\n",
    "    user_prompt = user_prompt.format(question=question, context=context)\n",
    "    message = build_message(user_prompt=user_prompt, system_role=system_role)\n",
    "\n",
    "    with AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as client:\n",
    "\n",
    "        # call Azure OpenAI with the system prompt and user's question\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "\n",
    "    response = {\n",
    "        \"choices\": [\n",
    "            {\n",
    "                \"index\": 0,\n",
    "                \"message\": {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": chat_completion.choices[0].message.content,\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # add context in the returned response\n",
    "    context_dict = {\n",
    "        \"context\": context,\n",
    "        \"contexts\": contexts,\n",
    "        \"num_docs\": num_docs,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    response[\"choices\"][0][\"context\"] = context_dict\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_documents(question: str):\n",
    "    result = chat_completion(\n",
    "        question=question,\n",
    "        system_role=model_config[\"prompt\"][\"system_role\"],\n",
    "        user_prompt=model_config[\"prompt\"][\"user_prompt\"]\n",
    "        + \"\\n\\nQuestion:'{question}' \\n\\nContext: '{context}'\",\n",
    "        index_name=INDEX_NAME,\n",
    "        num_docs=model_config[\"rag\"][\"num_docs\"],\n",
    "        temperature=model_config[\"model\"][\"temperature\"],\n",
    "        max_tokens=model_config[\"model\"][\"max_tokens\"],\n",
    "    )\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answering on the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a Power Unit Manufacturer does not submit the Full Year Reporting Documentation by the deadline, the Cost Cap Administration will issue a late submission notice to the manufacturer. The manufacturer will then have 48 hours to provide a written explanation for the late submission. The Cost Cap Administration may grant an extension to the Full Year Reporting Deadline if satisfied with the explanation. However, if the manufacturer does not provide a written response within the specified time, provides an unsatisfactory response, or fails to submit the documentation by the Extended Reporting Deadline, they will have committed a Non-Submission Breach and will be referred to the Cost Cap Adjudication Panel. The panel may impose penalties such as Constructors' Championship points deduction, financial penalties, and other sporting penalties.\n"
     ]
    }
   ],
   "source": [
    "chat_with_documents(\n",
    "    question=\"What happens if a Power Unit Manufacturer does not submit the Full Year Reporting Documentation by the deadline? \",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
