{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from rag_ai_studio import build_cogsearch_index, chat_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"financial_regulations\"\n",
    "DATA_PATH = \"../../data/unstructured\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../configs/user_config.yaml\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "load_dotenv(\"../configs/environment_variables.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_documents(question: str):\n",
    "    result = chat_completion(\n",
    "        question=question,\n",
    "        system_role=model_config[\"prompt\"][\"system_role\"],\n",
    "        user_prompt=model_config[\"prompt\"][\"user_prompt\"]\n",
    "        + \"\\n\\nQuestion:'{question}' \\n\\nContext: '{context}'\",\n",
    "        index_name=INDEX_NAME,\n",
    "        num_docs=model_config[\"rag\"][\"num_docs\"],\n",
    "        temperature=model_config[\"model\"][\"temperature\"],\n",
    "        max_tokens=model_config[\"model\"][\"max_tokens\"],\n",
    "    )\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIClient: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "[DocumentChunksIterator::filter_extensions] Filtered 0 files out of 1\n",
      "[DocumentChunksIterator::crack_documents] Total time to load files: 0.003322124481201172\n",
      "{\n",
      "  \".txt\": 0.0,\n",
      "  \".md\": 0.0,\n",
      "  \".html\": 0.0,\n",
      "  \".htm\": 0.0,\n",
      "  \".py\": 0.0,\n",
      "  \".pdf\": 1.0,\n",
      "  \".ppt\": 0.0,\n",
      "  \".pptx\": 0.0,\n",
      "  \".doc\": 0.0,\n",
      "  \".docx\": 0.0,\n",
      "  \".xls\": 0.0,\n",
      "  \".xlsx\": 0.0\n",
      "}\n",
      "[DocumentChunksIterator::split_documents] Total time to split 62 documents into 161 chunks: 0.43684840202331543\n",
      "Processing document: CH3-data.pdf0\n",
      "Processing document: CH3-data.pdf1\n",
      "Processing document: CH3-data.pdf2\n",
      "Processing document: CH3-data.pdf3\n",
      "Processing document: CH3-data.pdf4\n",
      "Processing document: CH3-data.pdf5\n",
      "Processing document: CH3-data.pdf6\n",
      "Processing document: CH3-data.pdf7\n",
      "Processing document: CH3-data.pdf8\n",
      "Processing document: CH3-data.pdf9\n",
      "Processing document: CH3-data.pdf10\n",
      "Processing document: CH3-data.pdf11\n",
      "Processing document: CH3-data.pdf12\n",
      "Processing document: CH3-data.pdf13\n",
      "Processing document: CH3-data.pdf14\n",
      "Processing document: CH3-data.pdf15\n",
      "Processing document: CH3-data.pdf16\n",
      "Processing document: CH3-data.pdf17\n",
      "Processing document: CH3-data.pdf18\n",
      "Processing document: CH3-data.pdf19\n",
      "Processing document: CH3-data.pdf20\n",
      "Processing document: CH3-data.pdf21\n",
      "Processing document: CH3-data.pdf22\n",
      "Processing document: CH3-data.pdf23\n",
      "Processing document: CH3-data.pdf24\n",
      "Processing document: CH3-data.pdf25\n",
      "Processing document: CH3-data.pdf26\n",
      "Processing document: CH3-data.pdf27\n",
      "Processing document: CH3-data.pdf28\n",
      "Processing document: CH3-data.pdf29\n",
      "Processing document: CH3-data.pdf30\n",
      "Processing document: CH3-data.pdf31\n",
      "Processing document: CH3-data.pdf32\n",
      "Processing document: CH3-data.pdf33\n",
      "Processing document: CH3-data.pdf34\n",
      "Processing document: CH3-data.pdf35\n",
      "Processing document: CH3-data.pdf36\n",
      "Processing document: CH3-data.pdf37\n",
      "Processing document: CH3-data.pdf38\n",
      "Processing document: CH3-data.pdf39\n",
      "Processing document: CH3-data.pdf40\n",
      "Processing document: CH3-data.pdf41\n",
      "Processing document: CH3-data.pdf42\n",
      "Processing document: CH3-data.pdf43\n",
      "Processing document: CH3-data.pdf44\n",
      "Processing document: CH3-data.pdf45\n",
      "Processing document: CH3-data.pdf46\n",
      "Processing document: CH3-data.pdf47\n",
      "Processing document: CH3-data.pdf48\n",
      "Processing document: CH3-data.pdf49\n",
      "Processing document: CH3-data.pdf50\n",
      "Processing document: CH3-data.pdf51\n",
      "Processing document: CH3-data.pdf52\n",
      "Processing document: CH3-data.pdf53\n",
      "Processing document: CH3-data.pdf54\n",
      "Processing document: CH3-data.pdf55\n",
      "Processing document: CH3-data.pdf56\n",
      "Processing document: CH3-data.pdf57\n",
      "Processing document: CH3-data.pdf58\n",
      "Processing document: CH3-data.pdf59\n",
      "Processing document: CH3-data.pdf60\n",
      "Processing document: CH3-data.pdf61\n",
      "Processing document: CH3-data.pdf62\n",
      "Processing document: CH3-data.pdf63\n",
      "Processing document: CH3-data.pdf64\n",
      "Processing document: CH3-data.pdf65\n",
      "Processing document: CH3-data.pdf66\n",
      "Processing document: CH3-data.pdf67\n",
      "Processing document: CH3-data.pdf68\n",
      "Processing document: CH3-data.pdf69\n",
      "Processing document: CH3-data.pdf70\n",
      "Processing document: CH3-data.pdf71\n",
      "Processing document: CH3-data.pdf72\n",
      "Processing document: CH3-data.pdf73\n",
      "Processing document: CH3-data.pdf74\n",
      "Processing document: CH3-data.pdf75\n",
      "Processing document: CH3-data.pdf76\n",
      "Processing document: CH3-data.pdf77\n",
      "Processing document: CH3-data.pdf78\n",
      "Processing document: CH3-data.pdf79\n",
      "Processing document: CH3-data.pdf80\n",
      "Processing document: CH3-data.pdf81\n",
      "Processing document: CH3-data.pdf82\n",
      "Processing document: CH3-data.pdf83\n",
      "Processing document: CH3-data.pdf84\n",
      "Processing document: CH3-data.pdf85\n",
      "Processing document: CH3-data.pdf86\n",
      "Processing document: CH3-data.pdf87\n",
      "Processing document: CH3-data.pdf88\n",
      "Processing document: CH3-data.pdf89\n",
      "Processing document: CH3-data.pdf90\n",
      "Processing document: CH3-data.pdf91\n",
      "Processing document: CH3-data.pdf92\n",
      "Processing document: CH3-data.pdf93\n",
      "Processing document: CH3-data.pdf94\n",
      "Processing document: CH3-data.pdf95\n",
      "Processing document: CH3-data.pdf96\n",
      "Processing document: CH3-data.pdf97\n",
      "Processing document: CH3-data.pdf98\n",
      "Processing document: CH3-data.pdf99\n",
      "Processing document: CH3-data.pdf100\n",
      "Processing document: CH3-data.pdf101\n",
      "Processing document: CH3-data.pdf102\n",
      "Processing document: CH3-data.pdf103\n",
      "Processing document: CH3-data.pdf104\n",
      "Processing document: CH3-data.pdf105\n",
      "Processing document: CH3-data.pdf106\n",
      "Processing document: CH3-data.pdf107\n",
      "Processing document: CH3-data.pdf108\n",
      "Processing document: CH3-data.pdf109\n",
      "Processing document: CH3-data.pdf110\n",
      "Processing document: CH3-data.pdf111\n",
      "Processing document: CH3-data.pdf112\n",
      "Processing document: CH3-data.pdf113\n",
      "Processing document: CH3-data.pdf114\n",
      "Processing document: CH3-data.pdf115\n",
      "Processing document: CH3-data.pdf116\n",
      "Processing document: CH3-data.pdf117\n",
      "Processing document: CH3-data.pdf118\n",
      "Processing document: CH3-data.pdf119\n",
      "Processing document: CH3-data.pdf120\n",
      "Processing document: CH3-data.pdf121\n",
      "Processing document: CH3-data.pdf122\n",
      "Processing document: CH3-data.pdf123\n",
      "Processing document: CH3-data.pdf124\n",
      "Processing document: CH3-data.pdf125\n",
      "Processing document: CH3-data.pdf126\n",
      "Processing document: CH3-data.pdf127\n",
      "Processing document: CH3-data.pdf128\n",
      "Processing document: CH3-data.pdf129\n",
      "Processing document: CH3-data.pdf130\n",
      "Processing document: CH3-data.pdf131\n",
      "Processing document: CH3-data.pdf132\n",
      "Processing document: CH3-data.pdf133\n",
      "Processing document: CH3-data.pdf134\n",
      "Processing document: CH3-data.pdf135\n",
      "Processing document: CH3-data.pdf136\n",
      "Processing document: CH3-data.pdf137\n",
      "Processing document: CH3-data.pdf138\n",
      "Processing document: CH3-data.pdf139\n",
      "Processing document: CH3-data.pdf140\n",
      "Processing document: CH3-data.pdf141\n",
      "Processing document: CH3-data.pdf142\n",
      "Processing document: CH3-data.pdf143\n",
      "Processing document: CH3-data.pdf144\n",
      "Processing document: CH3-data.pdf145\n",
      "Processing document: CH3-data.pdf146\n",
      "Processing document: CH3-data.pdf147\n",
      "Processing document: CH3-data.pdf148\n",
      "Processing document: CH3-data.pdf149\n",
      "Processing document: CH3-data.pdf150\n",
      "Processing document: CH3-data.pdf151\n",
      "Processing document: CH3-data.pdf152\n",
      "Processing document: CH3-data.pdf153\n",
      "Processing document: CH3-data.pdf154\n",
      "Processing document: CH3-data.pdf155\n",
      "Processing document: CH3-data.pdf156\n",
      "Processing document: CH3-data.pdf157\n",
      "Processing document: CH3-data.pdf158\n",
      "Processing document: CH3-data.pdf159\n",
      "Processing document: CH3-data.pdf160\n",
      "Documents to embed: 161\n",
      "Documents reused: 0\n",
      "ActivityStarted, Embeddings.embed\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 1 documents.\n",
      "ActivityCompleted: Activity=Embeddings.embed, HowEnded=Success, Duration=12446.88 [ms]\n",
      "ActivityStarted, update_acs\n",
      "Updating ACS index\n",
      "Using Index fields: {\n",
      "  \"content\": \"content\",\n",
      "  \"url\": \"url\",\n",
      "  \"filename\": \"filepath\",\n",
      "  \"title\": \"title\",\n",
      "  \"metadata\": \"meta_json_string\",\n",
      "  \"embedding\": \"contentVector\"\n",
      "}\n",
      "Ensuring search index financial_regulations exists\n",
      "Creating financial_regulations search index\n",
      "Created financial_regulations search index\n",
      "0 documents from sources marked for deletion, adding individual documents marked for deletion\n",
      "Total 0 documents marked for deletion\n",
      "Documents include embeddings: True\n",
      "Processing documents from: CH3-data\n",
      "Sending 100 documents to ACS\n",
      "Uploaded 100 documents to ACS in 5.4498 seconds, 0 failed\n",
      "Uploaded documents\n",
      "Sending 61 documents to ACS\n",
      "Uploaded 61 documents to ACS in 2.1157 seconds, 0 failed\n",
      "Uploaded documents\n",
      "Built index from 161 documents and 161 chunks, took 7.5735 seconds\n",
      "Built index\n",
      "Writing MLIndex yaml\n",
      "ActivityCompleted: Activity=update_acs, HowEnded=Success, Duration=10373.7 [ms]\n",
      "ActivityStarted, MLIndex.__init__\n",
      "ActivityCompleted: Activity=MLIndex.__init__, HowEnded=Success, Duration=107.48 [ms]\n",
      "\u001b[32mUploading financial_regulations-mlindex (0.0 MBs): 100%|██████████| 833/833 [00:00<00:00, 3029.95it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index 'financial_regulations'\n",
      "Local Path: /mnt/e/Projects/MicrosoftHackathon/AOAIhack/Student/Resources/codes/notebooks/financial_regulations-mlindex\n",
      "Cloud Path: azureml://subscriptions/5f388ce8-ce4d-4fca-aff5-d39d62b5cb8e/resourcegroups/scb_openaihack_rg/workspaces/project-hack-test-openai/datastores/workspaceblobstore/paths/LocalUpload/b19aaca5c4f154b04d3671f267c15294/financial_regulations-mlindex/\n"
     ]
    }
   ],
   "source": [
    "build_cogsearch_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    path_to_data=DATA_PATH,\n",
    "    chunk_size=model_config[\"rag\"][\"chunk_size\"],\n",
    "    chunk_overlap=model_config[\"rag\"][\"chunk_overlap\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, the position requires 2-7 years of relevant Data Science experience.\n"
     ]
    }
   ],
   "source": [
    "chat_with_documents(\n",
    "    question=\"How much relevant Data Science experience is needed for this position?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
